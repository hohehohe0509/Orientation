{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "U2fIDpErjwRe"
      },
      "outputs": [],
      "source": [
        "''' Import keras to build a DL model '''\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "import numpy\n",
        "\n",
        "''' Build the Model by Sequential'''\n",
        "# 在 Keras 裡面我們可以很簡單的使用 Sequential 的方法建建立一個 Model\n",
        "model = Sequential()\n",
        "# 加入 hidden layer-1 of 512 neurons 並指定 input_dim 為 784\n",
        "model.add(Dense(512, input_dim=784))\n",
        "# 使用 'relu' 當作 activation function\n",
        "model.add(Activation('relu'))\n",
        "# 加入 hidden layer-2 of 256 neurons\n",
        "model.add(Dense(256))\n",
        "# 使用 'relu' 當作 activation function\n",
        "model.add(Activation('relu'))\n",
        "# 加入 hidden layer-3 of 128 neurons\n",
        "model.add(Dense(128))\n",
        "# 使用 'relu' 當作 activation function\n",
        "model.add(Activation('relu'))\n",
        "# 加入 output layer of 10 neurons\n",
        "model.add(Dense(10))\n",
        "# 使用 'softmax' 當作 activation function\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset processing\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "Y_train = tf.zeros([60000,10])\n",
        "Y_test = tf.zeros([10000,10])\n",
        "Y_train = Y_train.numpy()\n",
        "Y_test = Y_test.numpy()\n",
        "for index, i in enumerate(y_train):\n",
        "  Y_train[index,i] = 1\n",
        "for index, i in enumerate(y_test):\n",
        "  Y_test[index,i] = 1\n",
        "y_train = tf.convert_to_tensor(Y_train)\n",
        "y_test = tf.convert_to_tensor(Y_test)\n",
        "\n",
        "\n",
        "#Data normalization\n",
        "x_train, x_test = x_train/ 255.0, x_test/ 255.0"
      ],
      "metadata": {
        "id": "wwxiQy_Pp_mj"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義訓練方式  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 開始訓練  \n",
        "train_history = model.fit(x=tf.reshape(x_train,[-1,28*28]), y=y_train, validation_split=0.1, epochs=10, batch_size=300, verbose=2)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rEcWYdyp19u",
        "outputId": "fb1877d4-95e3-4c91-ca75-3cf86a7340d6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "180/180 - 4s - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0763 - val_accuracy: 0.9832 - 4s/epoch - 25ms/step\n",
            "Epoch 2/10\n",
            "180/180 - 3s - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0984 - val_accuracy: 0.9770 - 3s/epoch - 18ms/step\n",
            "Epoch 3/10\n",
            "180/180 - 3s - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.1091 - val_accuracy: 0.9770 - 3s/epoch - 19ms/step\n",
            "Epoch 4/10\n",
            "180/180 - 3s - loss: 0.0104 - accuracy: 0.9961 - val_loss: 0.0877 - val_accuracy: 0.9805 - 3s/epoch - 18ms/step\n",
            "Epoch 5/10\n",
            "180/180 - 3s - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0937 - val_accuracy: 0.9812 - 3s/epoch - 18ms/step\n",
            "Epoch 6/10\n",
            "180/180 - 3s - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0935 - val_accuracy: 0.9797 - 3s/epoch - 19ms/step\n",
            "Epoch 7/10\n",
            "180/180 - 3s - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0909 - val_accuracy: 0.9813 - 3s/epoch - 18ms/step\n",
            "Epoch 8/10\n",
            "180/180 - 3s - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0841 - val_accuracy: 0.9840 - 3s/epoch - 18ms/step\n",
            "Epoch 9/10\n",
            "180/180 - 3s - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.1195 - val_accuracy: 0.9765 - 3s/epoch - 19ms/step\n",
            "Epoch 10/10\n",
            "180/180 - 3s - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0942 - val_accuracy: 0.9813 - 3s/epoch - 18ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(tf.reshape(x_test,[-1,28*28]), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mhEOXjm1TGH",
        "outputId": "9601030a-c78e-4f87-9673-edc919ee613d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0928 - accuracy: 0.9790\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09280595928430557, 0.9789999723434448]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}